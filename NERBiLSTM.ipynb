{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35179, 17)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ner_dataset.csv', encoding='latin1')\n",
    "df = df.fillna(method='ffill')\n",
    "words = list(set(df['Word'].values))\n",
    "words.append('endpad')\n",
    "tags = list(set(df['Tag'].values))\n",
    "len(words), len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "grouped = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "sentences = [s for s in grouped]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(sentence) for sentence in sentences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtoidx = {word:idx for idx,word in enumerate(words)}\n",
    "tagtoidx = {tag:idx for idx,tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[wordtoidx[word[0]] for word in sentence] for sentence in sentences]\n",
    "Y = [[tagtoidx[word[2]] for word in sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences=X, maxlen=max_len, padding='post', value=len(words)-1)\n",
    "Y = pad_sequences(sequences=Y, maxlen=max_len, padding='post', value=tagtoidx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18138, 21441, 30502, 23536, 27650, 18086, 22918, 24158, 32529,\n",
       "       21745, 22640, 21974, 29234, 22639,  2642, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
       "       35178, 35178, 35178, 35178, 35178], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "len(X_train), len(Y_train)\n",
    "X_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 104)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 104, 50)           1758950   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 104, 50)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 104, 256)          183296    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 104, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 1,946,615\n",
      "Trainable params: 1,946,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "input_data = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=len(words), output_dim=50, input_length=max_len)(input_data)\n",
    "model = SpatialDropout1D(rate=0.1)(model)\n",
    "model = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(units=len(tags), activation='softmax'))(model)\n",
    "model = Model(input_data, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1349/1349 [==============================] - 313s 232ms/step - loss: 0.0931 - accuracy: 0.9798 - val_loss: 0.0313 - val_accuracy: 0.9911\n",
      "Epoch 2/3\n",
      "1349/1349 [==============================] - 319s 237ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
      "Epoch 3/3\n",
      "1349/1349 [==============================] - 333s 247ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0222 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff0c0996b50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test,Y_test),\n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pranshu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 5s 34ms/step - loss: 0.0222 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022176483646035194, 0.993327796459198]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in - O\n",
      "am - O\n",
      "trip - O\n",
      "want - O\n",
      "I - I-tim\n",
      "an - O\n",
      "fly - O\n",
      "Airbus - I-org\n",
      "a - O\n",
      "to - O\n",
      "London - I-geo\n",
      ". - O\n",
      "planning - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n",
      "endpad - O\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing User Input\n",
    "def word_to_idx(words_predict):\n",
    "    words_idx = np.full((max_len,), len(words)-1)\n",
    "    i = 0\n",
    "    for w in words_predict:\n",
    "        words_idx[i] = wordtoidx[w]\n",
    "        i += 1\n",
    "    return words_idx\n",
    "\n",
    "input_sentence = \"I want to fly in an Airbus. I am planning a trip to London\"\n",
    "words_predict = list(set(word_tokenize(input_sentence)))\n",
    "x_predict = word_to_idx(words_predict)\n",
    "p = model.predict(np.array(x_predict))\n",
    "p = np.argmax(p, axis=-1)\n",
    "for i in range(len(p)):\n",
    "    print(\"{} - {}\".format(words[x_predict[i]], tags[p[i][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
